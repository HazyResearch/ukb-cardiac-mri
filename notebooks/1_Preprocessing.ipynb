{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Weak Supervision\n",
    "\n",
    "In this notebook, we perform segmentation on the cardiac MRI images. \n",
    "\n",
    "As input, we expect gamma-corrected MRI images. As output, we save a list of `failed_indexes.npy` that could not be properly segmented and `vocab_matrix.npy`, which contains the region properties for the segmented aortic valve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# viz\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# segmentation \n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Specify the path to (a) input images and (b) output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_IMAGES_PATH = \"6_brightest_gamma_images.npy\"\n",
    "OUTPUT_DIR = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load(INPUT_IMAGES_PATH, mmap_mode='r')\n",
    "failed_indexes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perform segmentation using SKlearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_region_label(image):\n",
    "    try: \n",
    "        thresh = threshold_otsu(image)    \n",
    "    except: \n",
    "        raise ValueError('invalid image for otsu thresholding', np.max(image))\n",
    "    \n",
    "    bw = closing(image > thresh, square(2))        \n",
    "    region_label = label(bw, connectivity=2)\n",
    "    return region_label \n",
    "\n",
    "def extract_region_labels_from_images(images, indexes=None):\n",
    "    region_labels = np.empty(images.shape)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        sys.stdout.write('\\r' + str(i+1) + \" / \" + str(len(images)) + \" region labels extracted\")\n",
    "        sys.stdout.flush()\n",
    "        try: \n",
    "            region_labels[i] = extract_region_label(images[i])\n",
    "        except ValueError as err: \n",
    "            print ('\\r image', i, err.args)\n",
    "            failed_indexes.append((i, 'extract_region_label'))\n",
    "        \n",
    "    return region_labels\n",
    "\n",
    "region_labels = extract_region_labels_from_images(images) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract the vocab matrix from each segmented region label\n",
    "This section uses hand-tuned thresholds (defined in `find_target_region`) to select the correct segmented region from a number of candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_target_region(region_label, image):\n",
    "    ''' \n",
    "    Given region labels, extracts region of interest using the following steps: \n",
    "        1) filter out regions that are too small \n",
    "        2) filter out regions with absurdly large eccentricity (image artifcats)\n",
    "        3) narrow down to 2 brightest regions \n",
    "        4)  a) if regions are close to one another, pick one to right\n",
    "            b) else, pick region closest to bottom left corner\n",
    "            \n",
    "    TUNEABLE PARAMS:\n",
    "        - WIDTH_DELTA_THRESHOLD: num horizontal pixels between regions \n",
    "                to be considered 'close'\n",
    "        - HEIGHT_DELTA_THRESHOLD: num vertical pixels between regions \n",
    "                to be considered 'close'\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    # tune these params \n",
    "    WIDTH_DELTA_THRESHOLD = 25\n",
    "    HEIGHT_DELTA_THRESHOLD = 15\n",
    "    AREA_THRESHOLD = 30 \n",
    "    ECCENTRICITY_THRESHOLD = 0.98\n",
    "    \n",
    "    def two_regions_close(two_regions):\n",
    "        ''' Helper fn to determine if regions are considered 'close' '''\n",
    "        \n",
    "        if len(two_regions) != 2: return False\n",
    "        \n",
    "        width_delta = abs(two_regions[0].centroid[1] - two_regions[1].centroid[1])\n",
    "        height_delta = abs(two_regions[0].centroid[0] - two_regions[1].centroid[0])\n",
    "        return width_delta < WIDTH_DELTA_THRESHOLD \\\n",
    "                and height_delta < HEIGHT_DELTA_THRESHOLD\n",
    "        \n",
    "    regions = regionprops(region_label.astype(int), image)\n",
    "\n",
    "    # remove all blobs < 30 area and > 0.95 eccentricity\n",
    "    filtered = list(filter(lambda x: x.area >= AREA_THRESHOLD \n",
    "            and x.eccentricity < ECCENTRICITY_THRESHOLD, regions))\n",
    "    \n",
    "    if len(filtered) == 0: \n",
    "        raise ValueError('bad threshold', \n",
    "                [(r.area, r.eccentricity) for r in regions])\n",
    "    \n",
    "    # pick top 2 mean_intensity \n",
    "    sorted_mean_intensity = sorted(filtered, key=lambda x: -x.mean_intensity)[:2]\n",
    "    \n",
    "    if two_regions_close(sorted_mean_intensity):\n",
    "        # return right most\n",
    "        return sorted(sorted_mean_intensity, key=lambda x: -x.centroid[1])[0]\n",
    "    else: \n",
    "        # return botom-left most\n",
    "        bottom_left = np.array([image.shape[0], 0])\n",
    "        bottom_leftmost = sorted(sorted_mean_intensity, key=lambda x: np.linalg.norm(bottom_left - x.centroid))[0]\n",
    "\n",
    "        return bottom_leftmost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: you can specify whether you want to visualize the target region you've chosen with the `show_images` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_target_region(image, region):\n",
    "        # plot original and target region\n",
    "        fig, axes = plt.subplots(1)\n",
    "        axes.imshow(image)\n",
    "        \n",
    "        # draw bounding box \n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='red', linewidth=2)\n",
    "        axes.add_patch(rect)\n",
    "        plt.show()\n",
    "\n",
    "def extract_vocab_from_region_labels(region_labels, images, indexes=None, show_images=False):\n",
    "    def extract_vocab(region):\n",
    "        vocab = np.zeros(10)\n",
    "        fields = ['area', 'eccentricity', 'equivalent_diameter', 'extent', 'major_axis_length', 'minor_axis_length', 'perimeter', 'max_intensity', 'mean_intensity', 'min_intensity']\n",
    "        for i in range(10):\n",
    "            vocab[i] = region[fields[i]]\n",
    "        return vocab\n",
    "    \n",
    "    vocab_matrix = np.zeros((10, len(images)))\n",
    "    for i in range(len(images)):\n",
    "        sys.stdout.write('\\r' + str(i+1) + \" / \" + str(len(images)) + \" vocab extracted\\r\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        try: \n",
    "            region = find_target_region(region_labels[i], images[i])\n",
    "            \n",
    "            if show_images:\n",
    "                print (images[i].shape)\n",
    "                visualize_target_region(images[i], region)\n",
    "\n",
    "            vocab_matrix[:, i] = extract_vocab(region)\n",
    "        except ValueError as err: \n",
    "            print ('\\r image', i, err.args)\n",
    "            failed_indexes.append((i, 'find_target_region'))\n",
    "        \n",
    "    return vocab_matrix\n",
    "\n",
    "vocab_matrix = extract_vocab_from_region_labels(region_labels, images, show_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save `vocab_matrix` and `failed_indexes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(OUTPUT_DIR, 'vocab_matrix.npy')\n",
    "print ('saving vocab matrix to: %s' % out_file)\n",
    "np.save(out_file, vocab_matrix)\n",
    "\n",
    "if len(failed_indexes) > 0:\n",
    "    failed_indexes_file = os.path.join(OUTPUT_DIR, 'failed_indexes.npy')\n",
    "    print ('failed', len(failed_indexes), 'indexes:', failed_indexes)\n",
    "    print ('saving vocab matrix to: %s' % failed_indexes_file)\n",
    "    np.save(failed_indexes_file, np.array(failed_indexes)[:,0].astype(int)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
